{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32657f14",
   "metadata": {},
   "source": [
    "# “Should This Loan be Approved or Denied?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ea272",
   "metadata": {},
   "source": [
    "### Group Members: Dinesh Saraswat, Garima Vijay, Vinmathi Iyappan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d728c",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9029be",
   "metadata": {},
   "source": [
    "\n",
    "This project focuses on building a predictive model to estimate the Probability of Default (PD) for small business loans using historical data from the U.S. Small Business Administration (SBA). The initiative supports regulatory compliance under the Basel Framework and aids banks in optimizing loan approvals for profitability and financial stability.\n",
    "Small business loans inherently carry higher risk, making accurate PD predictions essential for:\n",
    "1. Bank Decision-Making: Reducing financial losses and determining suitable loan terms.\n",
    "2. Regulatory Compliance: Meeting Basel III Endgame's capital adequacy standards.\n",
    "3. Profit Maximization: Optimizing returns while minimizing defaults.\n",
    "Using SBA data spanning 1987–2014 (899,164 records, 27 features), we addressed challenges such as class imbalance, missing values, and data inconsistencies. A stratified sampling approach and robust data preprocessing pipelines ensured effective analysis and modeling.\n",
    "The CatBoost model emerged as the best performer, delivering an average profit of $7,588.25 with a custom-tuned threshold (0.41). It demonstrated balanced performance across sensitivity, specificity, and profitability, providing an effective tool for loan decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fcf04",
   "metadata": {},
   "source": [
    "# Procedures and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82822c53",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2000d",
   "metadata": {},
   "source": [
    "**Data cleaning:** \n",
    "1. **City and State Mapping**: Missing values in the City and State fields were filled using the first three digits of the ZIP code and external mapping data from the ‘L002 3-Digit ZIP Code Prefix Matrix.pdf’ to accurately understand the business geography.\n",
    "\n",
    "2. **ZIP Code Standardization**: ZIP codes with a length of 4 were prefixed with a 0 to make them 5 digits, adhering to the standard ZIP code format.\n",
    "\n",
    "3. **Approval Fiscal Year** (ApprovalFY)\n",
    "     Alphabet Removal: Alphabetic characters in ApprovalFY were replaced with empty strings to clean the data.\n",
    "     Type Conversion: The column was converted to integers for consistency.\n",
    "\n",
    "4. **Standardized Numeric Columns**: Columns such as BalanceGross, DisbursementGross, ChgOffPrinGr, GrAppv, and SBA_Appv were converted to numeric by removing dollar signs and commas.\n",
    "\n",
    "5. **LowDoc Cleanup**: Errors in the LowDoc column (expected to contain 'Y' or 'N') were corrected. Loans with approval amounts less than \"150,000 dollars\" were flagged as \"Low Docs\".\n",
    "\n",
    "6. **Term Adjustment**: Terms less than 6 months were deemed erroneous so we updated to 6 months.\n",
    "\n",
    "7. **MIS_Status Conversion**: Converted MIS_Status to binary (1 for defaulted, 0 for paid in full) for easier modeling and analysis.\n",
    "\n",
    "8. **Records with missing values** in key fields like BankState, DisbursementDate, State, and City were dropped.\n",
    "\n",
    "9. Missing values in the NewExists field were filled with 0(means undefined)\n",
    "\n",
    "**New fields**\n",
    "\n",
    "10. **SBA Portion Calculation**: A new field (SBA_portion) was created to represent the percentage of the approved gross amount covered by SBA.\n",
    "\n",
    "11. **Recession Indicator**: A new field (recession) was created to flag loans with a maturity date between 2007-12-01 and 2009-06-30 as occurring during the recession.\n",
    "\n",
    "12. **Real Estate Indicator**: Loans with a term greater than 240 months were flagged with a new RealEstate column, indicating they were backed by real estate.\n",
    "\n",
    "13. **Franchise Flag**: A new field (If_Franchise) was created to indicate whether a loan was associated with a franchise (FranchiseCode not equal to 0 or 1).\n",
    "\n",
    "14. **Revolving Line of Credit**: A new column (correct_RevLineCr) was created to flag loans as part of a revolving line of credit based on predefined codes.\n",
    "\n",
    "15. **Industry Consolidation**: Industries based on the NAICS column were grouped into 7 major categories, consolidating the less frequent ones into an \"Other\" bucket to optimize category sizing and reduce complexity.\n",
    "\n",
    "16. **DefaultRateBucket**: This column categorizes each state into buckets based on default rate levels.\n",
    "\n",
    "17. **CompanySize**: Categorized businesses into size groups based on the number of employees.\n",
    "\n",
    "    **Logic**:\n",
    "    0: No employees (smallest businesses).\n",
    "    1: Micro-businesses (1–5 employees).\n",
    "    2: Small businesses (6–50 employees).\n",
    "    3: Medium-sized businesses (51–250 employees).\n",
    "    4: Large businesses (more than 250 employees).\n",
    "\n",
    "18. **Job Created** - Group businesses by the number of jobs created\n",
    "\n",
    "    **Logic**:\n",
    "    0: No or minimal job creation (0–1 jobs).\n",
    "    1: Small job creation (2–10 jobs).\n",
    "    2: Moderate job creation (11–20 jobs).\n",
    "    3: Significant job creation (more than 20 jobs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a300872",
   "metadata": {},
   "source": [
    "**Predictors**: \n",
    "\n",
    "1. **categorical** = ['NewExist']\n",
    "2. **label attributes** = [ 'IndustryFlag', 'CompanySize', 'DefaultRateBucket']\n",
    "3. **log attributes** = ['updated_term', 'DisbursementGross']\n",
    "4. **quantitative** = ['SBA_portion']\n",
    "5. **pass(as they are already labeled)** = ['recession', 'RealEstate', 'LowDoc_correct', 'correct_RevLineCr', 'If_Franchise', 'JOB_CREATED']\n",
    "\n",
    "    These variables are influential and consolidates most information from the given dataset\n",
    "\n",
    "**Key Points About the Data Transformations Before the Model**\n",
    "\n",
    "1. **Handling Categorical Variables:*\n",
    "    *Label Encoding**:\n",
    "     Columns 'IndustryFlag', 'CompanySize', 'DefaultRateBucket' are transformed into numerical format using LabelEncoder.\n",
    "     Ensures compatibility with models that require numerical inputs while preserving categorical relationships.\n",
    "\n",
    "2.\t**One-Hot Encoding**:\n",
    "    Columns 'NewExist', 'UrbanRural' are transformed into binary dummy variables using OneHotEncoder.\n",
    "    Allows models to interpret categories as separate features without assuming ordinal relationships.\n",
    "\n",
    "3. **Log Transformation for Highly Skewed Features**:\n",
    "    Columns 'updated_term', 'DisbursementGross' , 'SBA_portion' are transformed using the Yeo-Johnson PowerTransformer.\n",
    "    Handles positive and negative values, reducing skewness and stabilizing variance for highly skewed numeric data.\n",
    "\n",
    "4. Standard Scaler is used to normalize predictors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fa693",
   "metadata": {},
   "source": [
    "## Data Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a24289",
   "metadata": {},
   "source": [
    "Stratified sampling was employed to reduce the dataset size while preserving the distribution of loan outcomes\n",
    "and critical features that were highly imbalanced. This approach ensures that the sample maintains the same \n",
    "proportions of key variables as in the original dataset, which is particularly important when dealing with\n",
    "imbalanced data, like loan defaults (MIS_Status) and other influential categorical variables.\n",
    "\n",
    "Stratification was performed based on the following group of variables, which were highly imbalanced:\n",
    "'NewExist', 'UrbanRural', 'LowDoc_correct', 'RealEstate', 'recession', 'If_Franchise', \n",
    "'correct_RevLineCr', 'CompanySize', 'JOB_CREATED', 'MIS_Status', 'DefaultRateBucket', 'IndustryFlag'.\n",
    "By preserving the proportions of these variables in the sample, we ensure that the model is trained on a \n",
    "representative subset, which helps prevent biased learning and overfitting to the dominant class.\n",
    "\n",
    "**Group by multiple attributes to ensure balanced sampling**\n",
    "group_columns = ['NewExist', 'UrbanRural', 'LowDoc_correct', 'RealEstate', 'recession', 'If_Franchise',\n",
    "                 'correct_RevLineCr', 'CompanySize', 'JOB_CREATED', 'MIS_Status', 'DefaultRateBucket', 'IndustryFlag']\n",
    "\n",
    "Apply stratified sampling using Dask to reduce the dataset size (89348 (10% of the dataset)) while \n",
    "preserving key feature distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffcb4aa",
   "metadata": {},
   "source": [
    "## Defined Business Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c6e8b",
   "metadata": {},
   "source": [
    "We developed a custom business metric to evaluate financial impact:\n",
    "\n",
    "1. Correct Approvals: 5% profit of loan amounts.\n",
    "2. Incorrect Defaults: Losses at 5x loan amounts.\n",
    "3. Denied Loans: 0\n",
    "\n",
    "*Equation:*\n",
    "1. denied_correctly =  0  # No profit or loss for denying defaults\n",
    "2. denied_incorrectly = - 5 * 0.05 * disbursement_gross[false_negative].sum()  # Loss for incorrectly granting defaults\n",
    "3. approved_incorectly = 0  # No profit or loss for denying Paid in Full\n",
    "4. approved_correctly = (0.05 * disbursement_gross[true_negative]).sum()  # Profit for correctly granting Paid in Full\n",
    "\n",
    "**total_profit = denied_correctly + denied_incorrectly + approved_incorectly + approved_correctly**\n",
    "\n",
    "The **make_scorer** function in scikit-learn is used to create a custom scoring function that allowed us to define a \n",
    "performance metric tailored to the specific needs. \n",
    "business_scorer = make_scorer(business_metric).set_score_request(disbursement_gross=True)\n",
    "\n",
    "To further optimize profitability, **TunedThresholdClassifierCV** from Scikit Learn is used to fine-tune the decision threshold based on a business-specific metric. This approach helped identify the optimal threshold, balancing sensitivity and profitability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145a427",
   "metadata": {},
   "source": [
    "## Modeling and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84783a",
   "metadata": {},
   "source": [
    "Various machine learning models were evaluated using traditional performance metrics and the custom business metric. \n",
    "CatBoost outperformed all others, achieving:\n",
    "    \n",
    "**Default Threshold (0.5)**:\n",
    "1. Business Metric: $7,554.98 average profit.\n",
    "2. Accuracy: 91.83%\n",
    "3. Sensitivity: 91.51%\n",
    "4. Specificity: 91.91%\n",
    "5. F1 Score: 79.51%\n",
    "\n",
    "**Tuned Threshold (0.41)**:\n",
    "1. Business Metric: $7,588.25 average profit.\n",
    "2. Accuracy: 90.55%\n",
    "3. Sensitivity: 93.22%\n",
    "4. Specificity: 89.99%\n",
    "5. F1 Score: 77.35%\n",
    "\n",
    "**Best parameters**:\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,               \n",
    "    learning_rate=0.1,            \n",
    "    depth=6,\n",
    "    loss_function='Logloss',      \n",
    "    eval_metric='AUC'\n",
    "    random_seed=42,\n",
    "    verbose=100,                  \n",
    "    class_weights=[1, 5],         \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ce997",
   "metadata": {},
   "source": [
    "# Output and Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a5611",
   "metadata": {},
   "source": [
    "The optimized CatBoost model effectively predicts default probabilities for small business loans, balancing accuracy and profitability.\n",
    "\n",
    "1. The tuned threshold of 0.41 delivers higher sensitivity (93.22%), improving default identification and reducing losses.\n",
    "\n",
    "2. Profitability increased to $7,588.25 on average, demonstrating its practical utility for decision-making.\n",
    "\n",
    "**Trade-Off Analysis**\n",
    "The selection of a tuned threshold (0.41) was guided by the primary goal of maximizing profitability while maintaining strong predictive performance. This adjustment in the decision threshold demonstrates a deliberate trade-off between key metrics such as sensitivity, precision, and specificity to align the model's output with business objectives.\n",
    "\n",
    "**Prioritizing Sensitivity**\n",
    "\n",
    "1. Sensitivity, also known as the true positive rate, measures the model’s ability to correctly identify loan defaults.\n",
    "\n",
    "2. A higher sensitivity at the tuned threshold (93.22% vs. 91.51% at 0.5) indicates that the model is better at flagging loans that are likely to default.\n",
    "\n",
    "3. This improvement is crucial because missed defaults (false negatives) have the largest financial impact, representing loans that are incorrectly approved and result in substantial losses (5x the loan amount in this scenario).\n",
    "\n",
    "By increasing sensitivity, the model effectively reduces the occurrence of false negatives, minimizing these high-cost mistakes. This prioritization directly translates into greater financial gains, as evidenced by the increase in the business metric (profit improved by $33.27 on average).\n",
    "\n",
    "**Accepting Reductions in Precision and Specificity**\n",
    "1. Precision measures how many predicted defaults were actual defaults. At the tuned threshold, precision dropped slightly from 70.29% to 66.09%, reflecting a higher number of false positives (loans flagged as defaults but not actually defaulting).\n",
    "\n",
    "2. Specificity, which measures the ability to correctly identify non-defaults (loans likely to be fully paid), also saw a minor decrease from 91.91% to 89.99%.\n",
    "\n",
    "These reductions indicate that the model occasionally misclassifies some loans as defaults that might have been successfully repaid. However, the financial impact of such false positives is negligible compared to the cost of missed defaults. Denying these loans has no associated profit or loss in the business metric, making this trade-off acceptable.\n",
    "\n",
    "1. CatBoost clearly stands out with an exceptional ROC-AUC of 0.9713, indicating outstanding model performance.\n",
    "2.  It outperforms other models not just in ROC-AUC, but also delivers the highest profitability of **7,588.25 dollars**, making it the best for business purposes.\n",
    "3. It balances high accuracy, good sensitivity, and high specificity, which means it is both effective and reliable for predicting defaults without many false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354d4b6",
   "metadata": {},
   "source": [
    "### Other Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede71e5",
   "metadata": {},
   "source": [
    "1. **Logistic Regression Models**\n",
    "Three logistic regression models were evaluated for predicting defaults:\n",
    "\n",
    "*Baseline Logistic Regression (No Class Weights):*\n",
    "\n",
    "**Performance Highlights**:\n",
    "1. ROC-AUC: 0.8443.\n",
    "2. Tuned Threshold (0.18): Improved sensitivity to 80.38% and profitability to $5,460.23.\n",
    "3. While effective, it struggled to fully balance sensitivity and precision.\n",
    "4. Logistic Regression with Class Weights ({0: 1, 1: 5}):\n",
    "\n",
    "**Performance Highlights**:\n",
    "1. ROC-AUC: 0.8489 (slight improvement over the baseline).\n",
    "2. Tuned Threshold (0.54): Sensitivity of 78.31% and the highest business benefit of $5,619.83.\n",
    "3. This model best addressed class imbalance, achieving the highest profitability and balanced performance.\n",
    "4. Optimized Logistic Regression (ElasticNet Regularization):\n",
    "\n",
    "**Performance Highlights**:\n",
    "1. ROC-AUC: 0.8466.\n",
    "2. Tuned Threshold (0.18): Sensitivity of 80.35% and profitability of $5,457.37.\n",
    "3. Despite advanced tuning, performance gains over simpler models were marginal.\n",
    "\n",
    "________________________________________\n",
    "\n",
    "2. **KNN**\n",
    "\n",
    "The kNN model underwent a series of improvements to enhance its prediction accuracy, particularly in identifying defaults.\n",
    "1. Initially, with default settings and a threshold of 0.5, the model achieved an ROC-AUC of 0.8318, with high specificity (95.65%) but low sensitivity (47.40%), missing a significant number of defaults. The business benefit at this threshold was $4,697.87.\n",
    "\n",
    "2. After tuning the threshold to 0.2, sensitivity improved dramatically to 82.88%, increasing the business benefit to $5,230.82. Further hyperparameter tuning identified the optimal k=9 with a Manhattan distance metric, which led to an accuracy of 87.68%, but sensitivity remained low at 46.02%.\n",
    "\n",
    "3. However, the best model came from adjusting the threshold to 0.16, which yielded the highest sensitivity (77.58%) and an F1-Score of 60.32%. This model resulted in a business benefit of $5,686.10, showcasing the potential of kNN when optimized for specific business objectives, though it still underperformed compared to CatBoost in terms of overall performance.\n",
    "\n",
    "________________________________________\n",
    "\n",
    "3. **Random Forest**\n",
    "\n",
    "1. The Random Forest model, using class weights to address the imbalanced nature of the dataset, performed well in terms of ROC-AUC and overall accuracy. Initially, with a cutoff threshold of 0.5, the model achieved an ROC-AUC score of 0.9554 and a business benefit of $6,070.57. The accuracy was 87.68%, but sensitivity was lower at 46.02%, indicating the model missed a significant number of defaults. The specificity was high (96.39%), demonstrating strong performance in predicting non-defaults.\n",
    "\n",
    "2. When the decision threshold was tuned to 0.17, sensitivity increased substantially to 77.06%, reflecting the model's better ability to capture defaults. Precision also improved to 50.21%, and the F1-Score reached 0.6081, indicating a better balance between sensitivity and precision. The business benefit with the tuned threshold was $7,052.45, making it a more effective model for the goal of reducing defaults while still achieving acceptable specificity (84.02%).\n",
    "\n",
    "3. This model demonstrated the importance of threshold tuning to balance sensitivity and specificity, improving performance for the classification task.\n",
    "________________________________________\n",
    "4. **XGBoost**\n",
    "\n",
    "1. The XGBoost model, configured with a cost-sensitive setting (using scale_pos_weight=5 to account for the misclassification cost of class 1), demonstrated strong performance in terms of both ROC-AUC and business metrics. The model achieved an impressive ROC-AUC score of 0.9658, indicating excellent discrimination between classes. With the default cutoff threshold of 0.5, the model reached an accuracy of 91.84%, with high sensitivity (91.51%) and specificity (91.91%). Precision stood at 70.29%, and the F1-Score was 0.7951, reflecting a good balance between precision and recall.\n",
    "\n",
    "2. When the decision threshold was tuned to 0.34, the model achieved even better sensitivity (94.87%), capturing more of the positive class, while precision decreased slightly to 61.74%. The F1-Score remained strong at 0.748, and specificity dropped slightly to 87.70%. The business benefit at the tuned threshold was slightly lower at 7,185.23 dollars, compared to 7,208.09 dollars with the default threshold.\n",
    "\n",
    "3. Overall, the XGBoost model showed excellent performance, with sensitivity particularly benefiting from the threshold adjustment, making it highly effective for identifying defaults while maintaining a reasonable level of precision and specificity.\n",
    "________________________________________\n",
    "5. **Bagging Classifier**\n",
    "\n",
    "1. The Bagging Classifier, utilizing a cost-sensitive Decision Tree as the base estimator, demonstrated strong performance in both ROC-AUC and business metrics. With a ROC-AUC score of 0.9591, the model effectively discriminated between the default and non-default classes. The default cutoff threshold of 0.5 resulted in an accuracy of 91.84%, with high sensitivity (91.51%) and specificity (91.91%). Precision was 70.29%, and the F1-Score was 0.7951.\n",
    "\n",
    "2. When the decision threshold was adjusted to 0.19, the model showed a significant increase in sensitivity (97.37%), making it more sensitive to the positive class. However, this also resulted in a slight decrease in precision (51.27%) and specificity (80.64%). The F1-Score at the tuned threshold was 0.6717, indicating a more conservative approach with a better trade-off between recall and precision. The business benefit at the tuned threshold increased to $7,340.89 from $6,591.01 at the default threshold.\n",
    "\n",
    "3. Overall, the Bagging Classifier performed well, with sensitivity greatly improving after the threshold tuning, making it a highly effective model for detecting defaults.\n",
    "________________________________________\n",
    "6. **Single Tree**\n",
    "\n",
    "1. The cost-sensitive Decision Tree model, with a class weight of 5x for the positive class, performed well across several evaluation metrics, delivering strong results with a ROC-AUC score of 0.9506.\n",
    "\n",
    "________________________________________\n",
    "7. **Neural Network**\n",
    "\n",
    "1. The neural network model performed reasonably well on the binary classification task, yielding an accuracy of 87.94% on the test set.\n",
    "\n",
    "    o\tTest Loss: 0.2934\n",
    "    o\tTest Accuracy: 87.94%\n",
    "\n",
    "2. The neural network model shows strong performance with a high test accuracy of nearly 88%, but the recall and precision for detecting defaults (Class 1) could be improved. The business metric reflects this as well, with a slightly lower value compared to some other models.\n",
    "\n",
    "________________________________________\n",
    "8. **Linear Discriminant Analysis**\n",
    "\n",
    "1. The LDA model has strong performance in detecting Class 0 (No Default) with high recall and precision but struggles with detecting defaults (Class 1), as indicated by the lower recall and precision for that class. The tuned threshold (0.18) improves the business metric, indicating better financial outcomes when adjusting for the imbalance between classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e92a2",
   "metadata": {},
   "source": [
    "## Final model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa1bfe",
   "metadata": {},
   "source": [
    "1. **Algorithm**: Catboost model ( train and test split - 70/30 ratio)\n",
    "    \n",
    "**Performance Metrics:**\n",
    "    \n",
    "Accuracy: 89.16%\n",
    "Precision: 98% for non-default loans (class 0) and 71% for default loans (class 1).\n",
    "Recall: 92% for both non-default and default loans.\n",
    "F1-Score:\n",
    "0.95 for non-default loans.\n",
    "0.80 for default loans.\n",
    "\n",
    "he model achieves a high recall for default loans (92%), critical for minimizing financial losses due to loan \n",
    "defaults.High precision for non-default loans (98%) ensures most approved loans generate profit.\n",
    "\n",
    "**Business Metric Evaluation**\n",
    "\n",
    "1. Threshold (Tuned): 0.44.\n",
    "2. This threshold was determined to maximize business profit based on cumulative net profit.\n",
    "3. Default Threshold Profit: 7,571.41 dollars.\n",
    "4. Tuned Threshold Profit: 7,586.61 dollars.\n",
    "\n",
    "Optimizing the threshold from the default value significantly improved business profit, demonstrating the \n",
    "importance of tailoring thresholds to business objectives.\n",
    "\n",
    "**Profit Optimization**\n",
    "\n",
    "1. Maximum Cumulative Profit: $134,036,359.15.\n",
    "2. Optimal Cutoff Probability: 0.4056.\n",
    "3. Optimal Number of Loans: 13,256.\n",
    "    \n",
    "These loans, selected using the tuned cutoff probability, balance the trade-off between granting loans \n",
    "to non-default borrowers and denying loans to potential defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129e5a0",
   "metadata": {},
   "source": [
    "# Answers Based on Model Results\n",
    "\n",
    "**a. How far into the validation data should you go to get maximum net profit?**\n",
    "\n",
    "To achieve the maximum cumulative net profit, the model suggests considering the first *13,256* loans from the validation dataset. These loans are ranked based on their predicted probabilities, prioritizing the least risky applications.\n",
    "\n",
    "**b. If this model is used to score future loan applicants, what “probability of success” cut-off should be used in granting the loan and extending credit?**\n",
    "\n",
    "The optimal \"probability of success\" cut-off for granting loans is *0.4056*. Loans with a predicted probability of success (non-default) greater than or equal to 40.56% should be approved to maximize net profit while minimizing risk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
